Dozens of Linux server system monitoring commands are built into the operating system.
Including the likes of *top* or *sar*. Or you can also use monitoring programs such as *glance* , *htop* or *Netdata*.

Four Linux system monitoring tools are important to learn in details : 

### Sar

#### What is Sar ? 

**Sar** stands for **System Activity Reporter**. It is a command-line utility for collecting, reporting, and analyzing system activity data on Linux systems. Sar is a part of the **Sysstat package**, which provides various system performance monitoring tools.

Sar gathers data on various system resources and activities, including CPU utilization, memory usage, disk I/O, network traffic, and more. It collects this data at regular intervals and stores it for later analysis. This historical data can be invaluable for diagnosing performance issues, identifying trends, and optimizing system resources.

#### How to install Sar ?

Install package :

```
sudo apt-get install sysstat
```

Enable sar in /etc/default/sysstat configuration file : 

```
ENABLE="true"
```

Default configurations work but if you want to change them, they are located in :

```
sudo cat /etc/cron.d/sysstat
sudo cat /etc/sysstatsysstat
```

By default, the `debian-sa1` script runs every 10 minutes and collects sar data for historical reference. This data is written to the `/var/log/sysstat/saXX` file, where `XX` is the day of the month. For example, if today is the 24th day of the month, `sa1` writes the sar data to `/var/log/sysstat/sa24`. To change the logging frequency to one minute, change `5-55/10` to `5-55/1`. To make it 2 minutes, change it to `5/55/2`, and so on.
#### How to use Sar ? 

The syntax to use sar is : 

```
sudo sar [option] -f /path/to/sar/file
```

If no sar file is specified it will display the current day sar file

![Sar Current Day](/Assets/sar_default.png)

Linux 6.8.4-200.fc39.x86_64 is the kernel version.
(fedora) is the hostname.
x86_64 is the system architecture.
(4 CPU) is the number of CPU cores available.

You can use man sar to delve into the possible options to use with sar.





### Vmstat

#### What is vmstat ?

vmstat reports information about processes, memory, paging, block IO, traps, disks and cpu activity.

The  first  report produced gives averages since the last reboot.  Additional reports give information on a sampling period of length delay.  The process and memory reports are instantaneous in either case.

#### How to install vmstat ?

In most linux distribution vmstat is installed by default but if it is not installed on your distro vmstat is included in the procps-ng package.

```
sudo apt install procps-ng
```

#### How to use vmstat ?

The syntax to use vmstat is as such : 

```
sudo vmstat [option] [delay] [count]
```

![Vmstat with count](/Assets/vmstat.png)

##### Procs

Statistics on running, waiting and blocked processes:

- "r": The run queue, the number of threads ready to be (or already) in "run" mode, waiting for cpu ressources.
- "b": The blocked queue (or wait queue), the number of threads waiting for ressources other than the CPU. For example, disk, memory, network.

##### Memory

Usage of physical and virtual memory, including swapping statistics:

- "swapd": Used swap space
- "free": Available memory
- "buff": Memory used in buffers
- "cache": Memory used in cache

##### Swap

Swap space usage :

- "si": "Swap in": Memory moved from swap to RAM to be used by active processes
- "so": "Swap out": Memory moved from RAM to swap to make room for other data in RAM.

##### IO

Statistics on input/output operations on devices:

- "bi": "Block in": Reading from block devices (hard disks) in KiB/s
- "bo": "Block out": Writing to block devices (hard disks) in KiB/s

##### System

CPU usage by the kernel and processes: 

- "in": "Interrupts": Number of interrupts generated by the system's I/O devices.
- "cs": "Context Switches": Number of context switches per second.

##### CPU

CPU usage:

- "us": "User time": Operations initiated in user mode : user programs, calculations, etc
- "sy": "System time": Operations initiated in kernel mode: socket creation, file opening, etc
- "id": "Idle": Time when the processor is idle.
- "wa": "Wait": Waiting for a ressource (disk, network, etc)
- "st": "Steal time": CPU time that has been "stolen" by virtual machines on the same physical host.
- "gu": "Guest time": CPU time used by guest processes, such as virtual machines or containers.


### Monitorix

#### What is Monitorix ?

As per the [Monitorix Website](https://www.monitorix.org): 

**Monitorix is a free, open source, lightweight system monitoring tool** designed to monitor as many services and system resources as possible. It has been created to be used under **production Linux/UNIX servers**, but due to its simplicity and small size can be used on **embedded devices** as well.

It consists mainly of two programs: a collector, called `monitorix`, which is a Perl daemon that is started automatically like any other system service, and a CGI script called `monitorix.cgi`. Monitorix includes its own HTTP server built in (which is listening by default on port 8080/TCP) to see the statistics graphs, so you aren't forced to install a third-party web server to use it. Just point your browser at `http://localhost:8080/monitorix`.

All of its development was initially created for monitoring Red Hat, Fedora and CentOS Linux systems, so this project was made keeping in mind these type of distributions. Today it runs on different GNU/Linux distributions and even in other UNIX systems like FreeBSD, OpenBSD and NetBSD.

It is currently in active development adding new features, new graphs and correcting bugs in the attempt to offer a great tool for daily systems administration.

Monitorix is an open source project and, just like any other open source project, anyone can contribute with his own time and knowledge.

#### How to install Monitorix ?

Install package :

```
sudo apt-get install monitorix
```

Either use the default config or change it on : 

```
/etc/monitorix/monitorix.conf
```

After that you can restart the monitorix service :

```
sudo systemctl enable monitorix
sudo service monitorix restart
```

#### How to use Monitorix ?

Access it via your browser :

```
http://ipaddress:8080/monitorix
```

![Monitorix Landing Page](/Assets/monitorix_landing.png)

Select All graphs or a particular graph and a time period and click ok :

![Monitorix Graphs ](/Assets/monitorix_graphs.png)


Monitorix can keep track of system load, kernel usage, filesystem usage, network traffic, netstat traffic and many more things.


### Nethogs

#### What is Nethogs ? 

As per the [Nethogs github page](https://github.com/raboof/nethogs :

NetHogs is a small 'net top' tool. Instead of breaking the traffic down per protocol or per subnet, like most tools do, **it groups bandwidth by process**.

NetHogs does not rely on a special kernel module to be loaded. If there's suddenly a lot of network traffic, you can fire up NetHogs and immediately see which PID is causing this. This makes it easy to identify programs that have gone wild and are suddenly taking up your bandwidth.

Since NetHogs heavily relies on `/proc`, most features are only available on Linux. NetHogs can be built on Mac OS X and FreeBSD, but it will only show connections, not processes.

#### How to install Nethogs

Clone the github repository : 

```
git clone https://github.com/raboof/nethogs
```

Install dependencies : 

```
sudo apt install gcc-c++ libpcap-devel ncurses-devel
```

Navigate to your nethogs folder  : 

```
cd /path/to/nethogs
make
sudo make install
hash -r
```

And then you can start nethogs :

```
sudo nethogs
```


#### How to use Nethogs ?

Nethogs can be used inside a shell or with a GUI ([using nethogs-qt](http://slist.lilotux.net/linux/nethogs-qt/index_en.html) ), the syntax for nethogs is as such : 

```
sudo nethogs [option] [port name]
```

By default, nethogs measures traffic from and to the eth0 interface ( if you are connected via ethernet ) port if no option or port name is specified.

![Nethogs Default](/Assets/nethogs_default.png)

Nethogs can also be used to monitor multiple network ports at once : 

```
sudo nethogs wlp3s0 tun0
```

![Nethogs Multiple Interface](/Assets/nethogs_multiple.png)


You can check the options by using man nethogs : 

![Nethogs Options](/Assets/nethogs_options.png)


### Why using Linux system monitoring programs ? 

Using Linux system monitoring programs serves several purposes:

#### - Ensuring System Stability and Performance: 
Monitoring programs help ensure that the Linux system is stable and performs optimally. By keeping track of various system metrics, administrators can identify performance bottlenecks, resource-intensive processes, and potential issues that may affect system stability.

#### - Resource Management: 
Monitoring programs track resource utilization such as CPU, memory, disk, and network usage. This helps administrators allocate resources efficiently, identify resource-hungry processes, and prevent resource exhaustion which could lead to system slowdowns or crashes.

#### - Troubleshooting and Debugging: 
When issues arise, monitoring programs provide valuable insights into the system's behavior, allowing administrators to troubleshoot and debug problems effectively. They can pinpoint the root cause of performance issues or failures by analyzing system metrics and logs.

#### - Capacity Planning:
By analyzing historical data collected by monitoring programs, administrators can forecast future resource requirements and plan capacity upgrades accordingly. This proactive approach helps prevent resource shortages and ensures smooth system operation even as workload demands fluctuate.

#### - Security Monitoring: 
Some monitoring programs offer security-related features, such as detecting unusual network activity, monitoring file integrity, and identifying potential security breaches. By keeping an eye on these aspects, administrators can enhance the overall security posture of the Linux system.


These programs track various metrics, including but not limited to:

#### - CPU Usage: Monitoring the utilization of the CPU helps identify processes that are consuming excessive CPU resources, which may indicate performance issues or rogue processes.

#### - Memory Usage: Monitoring memory usage helps administrators identify memory leaks, inefficient memory utilization by processes, and potential memory exhaustion situations.

#### - Disk I/O: Monitoring disk I/O allows administrators to track disk read/write operations and identify performance bottlenecks related to disk usage, such as slow disk access or high disk utilization.

#### - Network Activity: Monitoring network activity helps detect abnormal network behavior, such as unusually high traffic volume or suspicious connections, which could indicate security breaches or network performance issues.

#### - System Uptime: Tracking system uptime provides insights into system reliability and helps identify patterns of downtime or stability issues.

#### - Process Activity: Monitoring process activity allows administrators to track the behavior of running processes, including CPU and memory usage, execution status, and resource consumption.

#### - System Logs: Monitoring system logs helps identify errors, warnings, and other events that may indicate system issues or security threats.


Overall, Linux system monitoring programs play a crucial role in maintaining system health, optimizing performance, ensuring security, and facilitating effective troubleshooting and capacity planning.


Specifically, Linux system monitors look at:

- **Memory usage**
- **CPU usage**
- **Storage usage** including disk space and Input/Output Operations per Second (IOPS)
- **Network usage**

### Glances

#### What is Glances ?

According to [Glances Github](https://github.com/nicolargo/glances) :

**Glances** is an open-source system cross-platform monitoring tool. It allows real-time monitoring of various aspects of your system such as CPU, memory, disk, network usage etc. It also allows monitoring of running processes, logged in users, temperatures, voltages, fan speeds etc. It also supports container monitoring, it supports different container management systems such as Docker, LXC. The information is presented in an easy to read dashboard and can also be used for remote monitoring of systems via a web interface or command line interface. It is easy to install and use and can be customized to show only the information that you are interested in.

#### How to install Glances ?

```
pip install --user glances
```

Glances has multiple modules to enable optional features. You can install them all with :

```
pip install --user glances[all]
```

#### How to use Glances ? 

Glances can be started in your terminal :

```
glances
```

It can be started as a web server :

```
glances -w 
```

Or even as a server/client mode:

```
glances -s # On server side
glances -c <ip> # On client side
```

![Glances web server](/Assets/glances.png)

Some of the most useful interactive commands in Glances are :

- Up and Down arrow keys: move up and down the list of processes.
- Left and Right arrow keys: move to different columns of the processes list.
- Enter : To start filtering the processes list using regex.
- 1 : Toggle CPU display between a summary view and a per CPU view.
- 2 : Toggle the left side bar.
- 3 : Toggle "Quick Look" on the top bar, provides a graphical summary of a CPU and memory usage.
- 4 : Toggle everything but "Quick Look" and load displays on the top bar.
- 5 : Toggle the top bar. Display details about CPU, memory and load.
- 6 : Toggle GPU display mode. ( Only on system using gpu and with the appropriate module installed)

### Research questions

#### What are the main areas of concern when monitoring a system?

- **System Performance:**

Monitoring CPU usage, memory usage, disk I/O, and network traffic can help identify performance bottlenecks and potential resource exhaustion issues.

- **Security:**

Monitoring for suspicious activity such as unauthorized access attempts, changes to system files, and unusual network traffic patterns can help detect and prevent security breaches.

- **Availability:**

Monitoring system uptime and responsiveness can help ensure that critical services are available and that any downtime is minimized.

- **Ressource Usage:**

Monitoring disk space usage, file system integrity, and resource utilization by individual processes can help identify potential issues before they impact system performance or availability.

- **Logs and Events:**

Monitoring system logs and events can help track system activity, identify errors and anomalies, and facilitate troubleshooting and forensic analysis.

- **Network Traffic:**

Monitoring incoming and outgoing network traffic can help detect and prevent unauthorized access, network attacks, and data exfiltration attempts.

- **User Activity:**

Monitoring user login/logout events, privilege escalation attempts, and file access can help identify unauthorized or suspicious user activity.

- **Software and Patch Management:**

Monitoring for software vulnerabilities and outdated packages can help ensure that systems are properly patched and protected against known security threats.

- **Compliance:**

Monitoring system configurations and adherence to security policies can help ensure compliance with regulatory requirements and organizational security standards.

- **Performance Trends:**

Monitoring long-term performance trends can help identify patterns and anticipate future resource requirements, allowing for proactive capacity planning and optimization.
#### How can you check what are the most memory intensive running processes ?

To check the most memory-intensive running processes on a Linux system, you can use various commands and tools. Here are a few options:

```
top
```

This command provides a dynamic view of system processes, sorted by various metrics including memory usage. By default, processes are sorted by CPU usage, but you can press Shift + M to sort by memory usage. The processes consuming the most memory will be listed at the top.

![top command](/Assets/top.png)

```
ps aux --sort=-%mem
```

You can use the `ps` command with the `aux` flags to list all processes along with their memory usage. To sort processes by memory usage, you can pipe the output to the `sort` command.

![ps aux command](/Assets/ps.png)

```
pmap <pid>
```

The `pmap` command shows memory map of a process. By running `pmap` along with the process ID, you can see detailed information about the memory usage of a specific process.

![pmap command](/Assets/pmap.png)
#### What are log files? Where can you find them on a typical Linux system ?

Log files are files that record events, activities, and messages generated by various processes, services, and components on a computer system. These log files are essential for system administrators and developers to monitor and troubleshoot system behavior, diagnose problems, track security incidents, and analyze performance.

On a typical Linux system, log files are located in the /var/log directory. Here are some common log files and their purposes:

- **syslog**: The syslog file contains messages from the kernel and system services. It is a general-purpose system log that records a wide variety of system events, including system startups, shutdowns, kernel messages, and service status messages. On some systems, this file may be split into multiple files like syslog, messages, auth.log, etc.

- **auth.log**: This file contains authentication-related messages, such as login attempts, authentication failures, and user authentication events.

- **kern.log**: The kern.log file contains kernel-related messages, including kernel errors, warnings, and information about hardware events.

- **daemon.log**: The daemon.log file contains messages generated by system daemons, such as network services and background processes.

- **secure**: This file contains security-related messages, including authentication events, privilege escalations, and security policy violations.

- **apache2/access.log and apache2/error.log**: These files contain access and error logs for the Apache web server, respectively.

 - **mysql/error.log**: This file contains error messages and diagnostic information generated by the MySQL database server.

- **mail.log**: The mail.log file contains messages related to email delivery and mail server operations, such as sending, receiving, and delivering email messages.

- **cron**: The cron file contains messages related to cron jobs, which are scheduled tasks that run at specified intervals.


These are just a few examples of common log files found on a typical Linux system. The specific log files and their locations may vary depending on the Linux distribution and the configuration of the system's logging infrastructure.

#### How can you check who where the last connected users, what they did, when they left ?

```
last
# or 
last username
```

The last command provides a list of recent login sessions, including information such as the username, terminal, IP address (if applicable), login time, and logout time (if applicable).

```
lastlog
```

The `lastlog` command displays the last login times for all users on the system.


User login and logout events are typically logged in system log files such as /var/log/auth.log, /var/log/secure, or /var/log/syslog. You can search these log files for login and logout events using tools like grep or awk. For example:

```
grep "session opened" /var/log/auth.log
grep "session closed" /var/log/auth.log
```

The availability and location of log files may vary depending on the Linux distribution and system configuration. Additionally, viewing user activities such as commands executed during a session often requires more detailed auditing configurations and logging of shell histories, which may not be enabled by default on all systems.

#### What are the different metrics of health and performance of a system ?

The health and performance of a system can be measured using various metrics across different categories. Here are some of the key metrics used to assess the health and performance of a system:

##### CPU utilization

Measures the percentage of time the CPU spends executing instructions. High CPU utilization may indicate that the system is under heavy load, potentially leading to performance degradation.

##### Memory Usage

Tracks the amount of physical memory (RAM) being used by the system and processes. High memory usage can lead to swapping and decreased performance due to increased disk I/O.

##### Disk utilization

Monitors the usage of disk space and disk I/O operations. High disk utilization may indicate that the disk is reaching its capacity or that certain processes are performing excessive I/O operations.

##### Network throughput

Measures the amount of data transmitted and received over the network interface. High network throughput may indicate heavy network traffic and potential bottlenecks.

##### System load average

Represents the average number of processes waiting in the system's run queue over a certain period of time. A high load average relative to the number of CPU cores may indicate system overload and potential performance issues.

##### Process statistics

Includes metrics such as CPU and memory usage per process, number of running processes, and process states (e.g., running, sleeping, zombie). Monitoring individual processes can help identify resource-intensive or malfunctioning processes.

##### Filesystem usage

Tracks the usage of filesystems, including the amount of disk space used, available, and reserved. Monitoring filesystem usage helps prevent disk space exhaustion and potential system failures.

##### I/O wait

Measures the percentage of time the CPU spends waiting for I/O operations to complete. High I/O wait times may indicate disk I/O bottlenecks or slow storage devices.

##### Response time

Measures the time taken to respond to requests or execute commands. Monitoring response times for critical services helps ensure acceptable performance levels and user experience.

##### Error and warning messages

Monitors system logs for error and warning messages related to hardware failures, software issues, and other abnormalities. Timely detection and resolution of errors help maintain system stability and reliability.

These metrics provide insights into different aspects of system health and performance, allowing system administrators to identify issues, optimize resource usage, and ensure the smooth operation of the system. Various monitoring tools and utilities are available to collect and analyze these metrics in real-time or over time for performance tuning and troubleshooting purposes.

#### How can you check the uptime of a machine ?

You can check the uptime of a machine in Linux using the `uptime` command. Simply open a terminal and type:

```
uptime
```

This command will display the current time, how long the system has been running, the number of users currently logged in, and the system load averages for the past 1, 5, and 15 minutes.

![Uptime](/Assets/uptime.png)

#### How can you assess the network traffic ? 

##### Network Monitoring Tools

Utilize specialized network monitoring tools such as Wireshark, tcpdump, or ntop to capture and analyze network packets in real-time. These tools provide detailed insights into network traffic, including packet headers, protocols, source and destination IP addresses, ports, and payload data.

##### Flow-based Analysis

Use flow-based analysis tools such as NetFlow, sFlow, or IPFIX to collect and aggregate network traffic data at the flow level. Flow-based analysis provides summarized information about network conversations, including source and destination IP addresses, ports, protocols, and traffic volume.

##### Network Traffic Analysis Platforms

Deploy network traffic analysis platforms such as Suricata, Snort, or Bro IDS to detect and analyze network security threats, including intrusions, malware, and suspicious behavior. These platforms employ signature-based detection, anomaly detection, and behavioral analysis techniques to identify and respond to network security incidents.

##### Bandwidth Monitoring Tools

Use bandwidth monitoring tools such as Cacti, Nagios, or Zabbix to monitor network bandwidth utilization and performance metrics in real-time. These tools provide visualizations and reports to track bandwidth usage, identify bottlenecks, and optimize network resource allocation.

##### Protocol Analyzers

Employ protocol analyzers such as tcpdump, Wireshark, or ngrep to capture and analyze network traffic based on specific protocols or criteria. These tools allow you to filter and dissect network packets, extract relevant information, and troubleshoot protocol-related issues.

##### Network Traffic Shaping and QoS

Implement network traffic shaping and Quality of Service (QoS) mechanisms to prioritize and control the flow of network traffic based on predefined policies. Traffic shaping techniques such as traffic prioritization, rate limiting, and traffic classification help optimize network performance and ensure Quality of Service for critical applications.

## Work In Progress